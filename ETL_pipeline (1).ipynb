{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f81488d6-4f03-4296-a83f-772e1afcefc4",
   "metadata": {},
   "source": [
    "## Dataset Column Descriptions\n",
    "\n",
    "| **Column Name**        | **Description**                                                                |\n",
    "|------------------------|--------------------------------------------------------------------------------|\n",
    "| **flightdate**         | The date of the flight in YYYY-MM-DD format.                                   |\n",
    "| **day_of_week**        | The day of the week the flight occurred (e.g., Monday, Tuesday).               |\n",
    "| **airline**            | The airline operating the flight (e.g., Delta, United).                        |\n",
    "| **tail_number**        | The unique identifier for the aircraft.                                        |\n",
    "| **dep_airport**        | The IATA code of the departure airport.                                        |\n",
    "| **dep_cityname**       | The name of the city where the departure airport is located.                   |\n",
    "| **deptime_label**      | The time label of the flight's departure (e.g., morning, afternoon).           |\n",
    "| **dep_delay**          | The delay time in minutes for the departure.                                   |\n",
    "| **dep_delay_tag**      | Whether the flight was delayed or not.                                         |\n",
    "| **dep_delay_type**     | The severity of the delay time (e.g., low, medium, high).                      |\n",
    "| **arr_airport**        | The IATA code of the arrival airport.                                          |\n",
    "| **arr_cityname**       | The name of the city where the arrival airport is located.                     |\n",
    "| **arr_delay**          | The delay time in minutes for the arrival.                                     |\n",
    "| **arr_delay_type**     | The severity of the delay time (e.g., low, medium, high).                      |\n",
    "| **flight_duration**    | The total duration of the flight in minutes.                                   |\n",
    "| **distance_type**      | A classification of the flight's distance (e.g., short-haul, long-haul).       |\n",
    "| **delay_carrier**      | Delay time (in minutes) attributed to the carrier.                             |\n",
    "| **delay_weather**      | Delay time (in minutes) caused by weather conditions.                          |\n",
    "| **delay_nas**          | Delay time (in minutes) due to National Airspace System issues.                |\n",
    "| **delay_security**     | Delay time (in minutes) due to security-related issues.                        |\n",
    "| **delay_lastaircraft** | Delay time (in minutes) caused by the previous aircraft's issues.              |\n",
    "| **manufacturer**       | The manufacturer of the aircraft (e.g., Boeing, Airbus).                       |\n",
    "| **model**              | The specific model of the aircraft (e.g., 737-800, A320).                      |\n",
    "| **aicraft_age**        | The age of the aircraft in years.                                              |\n",
    "| **tavg**               | The average temperature (°C) on the flight date.                               |\n",
    "| **tmin**               | The minimum temperature (°C) on the flight date.                               |\n",
    "| **tmax**               | The maximum temperature (°C) on the flight date.                               |\n",
    "| **prcp**               | The amount of precipitation (mm) on the flight date.                           |\n",
    "| **snow**               | The amount of snowfall (mm) on the flight date.                                |\n",
    "| **wdir**               | The wind direction (degrees) on the flight date.                       |\n",
    "| **wspd**               | The wind speed (km/h) on the flight date.                              |\n",
    "| **pres**               | The atmospheric pressure (hPa) on the flight date.                             |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b8765-8c48-4bfc-a2ab-be1f771ae8c9",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d68ab1e-473a-4ddb-b000-bf7ded2bea93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "from botocore.exceptions import NoCredentialsError, ClientError\n",
    "import seaborn as sns\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression,\n",
    "    RandomForestClassifier,\n",
    "    GBTClassifier,\n",
    "    DecisionTreeClassifier\n",
    ")\n",
    "\n",
    "# For Pipeline and Feature Transformation\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    VectorAssembler,\n",
    "    StringIndexer,\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    RobustScaler\n",
    ")\n",
    "\n",
    "# For Model Evaluation\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "\n",
    "# For SQL and DataFrame Operations\n",
    "from pyspark.sql.functions import col, monotonically_increasing_id\n",
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b83e7d9e-821a-4d1c-83e8-81a363278dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89fc2ccd-2728-422f-a73c-b0e3664264b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/01/09 06:32:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 58864)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/accumulators.py\", line 281, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/accumulators.py\", line 253, in poll\n",
      "    if func():\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/accumulators.py\", line 257, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/serializers.py\", line 595, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Classification\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", True) \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"2g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.task.maxFailures\", \"4\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deb1132c-90e5-4619-807b-6620364d0ba9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc6f53f-fc49-42e8-8d55-df85958c1c06",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Data from S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94846c3b-294d-4383-a61c-f796183cbfc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = 'baobucketaws'\n",
    "prefix = 'asm3/raw/airport/'\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "\n",
    "def read_csv_from_s3_as_df(bucket, key):\n",
    "    try:\n",
    "        # Get the object from S3\n",
    "        obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "        # Read the contents of the file into a pandas DataFrame\n",
    "        df_pre_clean = pd.read_csv(BytesIO(obj['Body'].read()), header=0)\n",
    "\n",
    "        return df_pre_clean\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "    except ClientError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during DataFrame conversion: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9316998-f606-40a2-af17-f097e2412897",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated DataFrame:\n",
      "         FlightDate  Day_Of_Week                Airline Tail_Number  \\\n",
      "0        2023-01-02            1           Endeavor Air      N601LR   \n",
      "1        2023-01-03            2           Endeavor Air      N910XJ   \n",
      "2        2023-01-04            3           Endeavor Air      N607LR   \n",
      "3        2023-01-05            4           Endeavor Air      N600LR   \n",
      "4        2023-01-06            5           Endeavor Air      N607LR   \n",
      "...             ...          ...                    ...         ...   \n",
      "6743399  2023-12-19            2  Skywest Airlines Inc.      N507SY   \n",
      "6743400  2023-12-29            5  Skywest Airlines Inc.      N520SY   \n",
      "6743401  2023-12-22            5  Skywest Airlines Inc.      N706SK   \n",
      "6743402  2023-12-28            4  Skywest Airlines Inc.      N707SK   \n",
      "6743403  2023-12-29            5  Skywest Airlines Inc.      N719EV   \n",
      "\n",
      "        Dep_Airport                    Dep_CityName DepTime_label  Dep_Delay  \\\n",
      "0               ABE  Allentown/Bethlehem/Easton, PA     Afternoon         -5   \n",
      "1               ABE  Allentown/Bethlehem/Easton, PA     Afternoon         -4   \n",
      "2               ABE  Allentown/Bethlehem/Easton, PA     Afternoon          9   \n",
      "3               ABE  Allentown/Bethlehem/Easton, PA     Afternoon         -5   \n",
      "4               ABE  Allentown/Bethlehem/Easton, PA     Afternoon         -7   \n",
      "...             ...                             ...           ...        ...   \n",
      "6743399         YUM                        Yuma, AZ     Afternoon         -4   \n",
      "6743400         YUM                        Yuma, AZ     Afternoon         19   \n",
      "6743401         YUM                        Yuma, AZ       Evening         45   \n",
      "6743402         YUM                        Yuma, AZ       Morning         -6   \n",
      "6743403         YUM                        Yuma, AZ       Morning         -4   \n",
      "\n",
      "         Dep_Delay_Tag Dep_Delay_Type Arr_Airport           Arr_CityName  \\\n",
      "0                    0      Low <5min         ATL            Atlanta, GA   \n",
      "1                    0      Low <5min         ATL            Atlanta, GA   \n",
      "2                    1      Low <5min         ATL            Atlanta, GA   \n",
      "3                    0      Low <5min         ATL            Atlanta, GA   \n",
      "4                    0      Low <5min         ATL            Atlanta, GA   \n",
      "...                ...            ...         ...                    ...   \n",
      "6743399              0      Low <5min         PHX            Phoenix, AZ   \n",
      "6743400              1  Medium >15min         PHX            Phoenix, AZ   \n",
      "6743401              1  Medium >15min         PHX            Phoenix, AZ   \n",
      "6743402              0      Low <5min         DFW  Dallas/Fort Worth, TX   \n",
      "6743403              0      Low <5min         DFW  Dallas/Fort Worth, TX   \n",
      "\n",
      "         Arr_Delay Arr_Delay_Type  Flight_Duration       Distance_type  \\\n",
      "0              -23      Low <5min              117  Short Haul >1500Mi   \n",
      "1               -5      Low <5min              134  Short Haul >1500Mi   \n",
      "2                1      Low <5min              127  Short Haul >1500Mi   \n",
      "3               12      Low <5min              152  Short Haul >1500Mi   \n",
      "4              -23      Low <5min              119  Short Haul >1500Mi   \n",
      "...            ...            ...              ...                 ...   \n",
      "6743399         -5      Low <5min               58  Short Haul >1500Mi   \n",
      "6743400         18  Medium >15min               59  Short Haul >1500Mi   \n",
      "6743401         49  Medium >15min               62  Short Haul >1500Mi   \n",
      "6743402        -24      Low <5min              141  Short Haul >1500Mi   \n",
      "6743403        -11      Low <5min              152  Short Haul >1500Mi   \n",
      "\n",
      "         Delay_Carrier  Delay_Weather  Delay_NAS  Delay_Security  \\\n",
      "0                    0              0          0               0   \n",
      "1                    0              0          0               0   \n",
      "2                    0              0          0               0   \n",
      "3                    0              0          0               0   \n",
      "4                    0              0          0               0   \n",
      "...                ...            ...        ...             ...   \n",
      "6743399              0              0          0               0   \n",
      "6743400             18              0          0               0   \n",
      "6743401              0              0          4               0   \n",
      "6743402              0              0          0               0   \n",
      "6743403              0              0          0               0   \n",
      "\n",
      "         Delay_LastAircraft           Manufacturer    Model  Aicraft_age  \\\n",
      "0                         0  CANADAIR REGIONAL JET      CRJ           17   \n",
      "1                         0  CANADAIR REGIONAL JET      CRJ           17   \n",
      "2                         0  CANADAIR REGIONAL JET      CRJ           16   \n",
      "3                         0  CANADAIR REGIONAL JET      CRJ           17   \n",
      "4                         0  CANADAIR REGIONAL JET      CRJ           16   \n",
      "...                     ...                    ...      ...          ...   \n",
      "6743399                   0                EMBRAER  170/175            3   \n",
      "6743400                   0                EMBRAER  170/175            2   \n",
      "6743401                  45  CANADAIR REGIONAL JET      CRJ           20   \n",
      "6743402                   0  CANADAIR REGIONAL JET      CRJ           25   \n",
      "6743403                   0  CANADAIR REGIONAL JET      CRJ           21   \n",
      "\n",
      "               time  tavg  tmin  tmax  prcp  snow   wdir  wspd    pres  \\\n",
      "0        2023-01-02   5.4   0.0  11.7   0.0   0.0  353.0   3.6  1019.6   \n",
      "1        2023-01-03   8.4   7.2   9.4  15.2   0.0   50.0   5.0  1013.9   \n",
      "2        2023-01-04  11.1   6.7  17.2   0.0   0.0  302.0   4.7  1009.8   \n",
      "3        2023-01-05  12.7   6.7  14.4   7.9   0.0  292.0   7.2  1013.0   \n",
      "4        2023-01-06   5.8   2.8   7.2   5.8   0.0  308.0   9.0  1016.6   \n",
      "...             ...   ...   ...   ...   ...   ...    ...   ...     ...   \n",
      "6743399  2023-12-19  16.5  12.0  24.4   0.0   0.0   43.0   5.8  1011.3   \n",
      "6743400  2023-12-29  13.6   7.0  20.2   0.0   0.0   22.0  13.7  1020.0   \n",
      "6743401  2023-12-22  14.4  12.0  16.1   8.6   0.0   53.0  13.9  1012.8   \n",
      "6743402  2023-12-28  12.8   6.7  21.0   0.0   0.0   12.0  11.1  1020.6   \n",
      "6743403  2023-12-29  13.6   7.0  20.2   0.0   0.0   22.0  13.7  1020.0   \n",
      "\n",
      "        airport_id  \n",
      "0              ABE  \n",
      "1              ABE  \n",
      "2              ABE  \n",
      "3              ABE  \n",
      "4              ABE  \n",
      "...            ...  \n",
      "6743399        YUM  \n",
      "6743400        YUM  \n",
      "6743401        YUM  \n",
      "6743402        YUM  \n",
      "6743403        YUM  \n",
      "\n",
      "[6743404 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "def list_s3_csv_files(bucket, prefix):\n",
    "    try:\n",
    "        response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "        if 'Contents' in response:\n",
    "            return [obj['Key'] for obj in response['Contents'] if obj['Key'].endswith('.csv')]\n",
    "        else:\n",
    "            return []\n",
    "    except ClientError as e:\n",
    "        print(f\"An error occurred while listing files: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# Fetch all CSV files in the folder\n",
    "csv_keys = list_s3_csv_files(bucket, prefix)\n",
    "\n",
    "# Initialize an empty list to hold DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Read and concatenate all CSV files\n",
    "for key in csv_keys:\n",
    "    df = read_csv_from_s3_as_df(bucket, key)\n",
    "    if df is not None:\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "if dataframes:\n",
    "    concatenated_df = pd.concat(dataframes, ignore_index=True)\n",
    "    print(\"Concatenated DataFrame:\")\n",
    "    print(concatenated_df)\n",
    "else:\n",
    "    print(\"No dataframes to concatenate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3ecbe6-e72f-411b-a56e-7acce8dc3766",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae92caff-24e5-4ff8-8f8b-371772b6eebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14dab61e-71a2-40c1-8a5d-8baf9e9b13e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73efa34f-ddfa-42be-87c9-af864e491cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flightdate</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>airline</th>\n",
       "      <th>tail_number</th>\n",
       "      <th>dep_airport</th>\n",
       "      <th>dep_cityname</th>\n",
       "      <th>deptime_label</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>dep_delay_tag</th>\n",
       "      <th>dep_delay_type</th>\n",
       "      <th>arr_airport</th>\n",
       "      <th>arr_cityname</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>arr_delay_type</th>\n",
       "      <th>flight_duration</th>\n",
       "      <th>distance_type</th>\n",
       "      <th>delay_carrier</th>\n",
       "      <th>delay_weather</th>\n",
       "      <th>delay_nas</th>\n",
       "      <th>delay_security</th>\n",
       "      <th>delay_lastaircraft</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>aicraft_age</th>\n",
       "      <th>time</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>snow</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "      <th>airport_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>Endeavor Air</td>\n",
       "      <td>N601LR</td>\n",
       "      <td>ABE</td>\n",
       "      <td>Allentown/Bethlehem/Easton, PA</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>-23</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>117</td>\n",
       "      <td>Short Haul &gt;1500Mi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CANADAIR REGIONAL JET</td>\n",
       "      <td>CRJ</td>\n",
       "      <td>17</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1019.6</td>\n",
       "      <td>ABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>2</td>\n",
       "      <td>Endeavor Air</td>\n",
       "      <td>N910XJ</td>\n",
       "      <td>ABE</td>\n",
       "      <td>Allentown/Bethlehem/Easton, PA</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>-4</td>\n",
       "      <td>0</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>-5</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>134</td>\n",
       "      <td>Short Haul &gt;1500Mi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CANADAIR REGIONAL JET</td>\n",
       "      <td>CRJ</td>\n",
       "      <td>17</td>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>15.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1013.9</td>\n",
       "      <td>ABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>3</td>\n",
       "      <td>Endeavor Air</td>\n",
       "      <td>N607LR</td>\n",
       "      <td>ABE</td>\n",
       "      <td>Allentown/Bethlehem/Easton, PA</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>1</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>127</td>\n",
       "      <td>Short Haul &gt;1500Mi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CANADAIR REGIONAL JET</td>\n",
       "      <td>CRJ</td>\n",
       "      <td>16</td>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>17.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1009.8</td>\n",
       "      <td>ABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>4</td>\n",
       "      <td>Endeavor Air</td>\n",
       "      <td>N600LR</td>\n",
       "      <td>ABE</td>\n",
       "      <td>Allentown/Bethlehem/Easton, PA</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>12</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>152</td>\n",
       "      <td>Short Haul &gt;1500Mi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CANADAIR REGIONAL JET</td>\n",
       "      <td>CRJ</td>\n",
       "      <td>17</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>12.7</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.4</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>ABE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>5</td>\n",
       "      <td>Endeavor Air</td>\n",
       "      <td>N607LR</td>\n",
       "      <td>ABE</td>\n",
       "      <td>Allentown/Bethlehem/Easton, PA</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>-23</td>\n",
       "      <td>Low &lt;5min</td>\n",
       "      <td>119</td>\n",
       "      <td>Short Haul &gt;1500Mi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CANADAIR REGIONAL JET</td>\n",
       "      <td>CRJ</td>\n",
       "      <td>16</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1016.6</td>\n",
       "      <td>ABE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flightdate  day_of_week       airline tail_number dep_airport  \\\n",
       "0  2023-01-02            1  Endeavor Air      N601LR         ABE   \n",
       "1  2023-01-03            2  Endeavor Air      N910XJ         ABE   \n",
       "2  2023-01-04            3  Endeavor Air      N607LR         ABE   \n",
       "3  2023-01-05            4  Endeavor Air      N600LR         ABE   \n",
       "4  2023-01-06            5  Endeavor Air      N607LR         ABE   \n",
       "\n",
       "                     dep_cityname deptime_label  dep_delay  dep_delay_tag  \\\n",
       "0  Allentown/Bethlehem/Easton, PA     Afternoon         -5              0   \n",
       "1  Allentown/Bethlehem/Easton, PA     Afternoon         -4              0   \n",
       "2  Allentown/Bethlehem/Easton, PA     Afternoon          9              1   \n",
       "3  Allentown/Bethlehem/Easton, PA     Afternoon         -5              0   \n",
       "4  Allentown/Bethlehem/Easton, PA     Afternoon         -7              0   \n",
       "\n",
       "  dep_delay_type arr_airport arr_cityname  arr_delay arr_delay_type  \\\n",
       "0      Low <5min         ATL  Atlanta, GA        -23      Low <5min   \n",
       "1      Low <5min         ATL  Atlanta, GA         -5      Low <5min   \n",
       "2      Low <5min         ATL  Atlanta, GA          1      Low <5min   \n",
       "3      Low <5min         ATL  Atlanta, GA         12      Low <5min   \n",
       "4      Low <5min         ATL  Atlanta, GA        -23      Low <5min   \n",
       "\n",
       "   flight_duration       distance_type  delay_carrier  delay_weather  \\\n",
       "0              117  Short Haul >1500Mi              0              0   \n",
       "1              134  Short Haul >1500Mi              0              0   \n",
       "2              127  Short Haul >1500Mi              0              0   \n",
       "3              152  Short Haul >1500Mi              0              0   \n",
       "4              119  Short Haul >1500Mi              0              0   \n",
       "\n",
       "   delay_nas  delay_security  delay_lastaircraft           manufacturer model  \\\n",
       "0          0               0                   0  CANADAIR REGIONAL JET   CRJ   \n",
       "1          0               0                   0  CANADAIR REGIONAL JET   CRJ   \n",
       "2          0               0                   0  CANADAIR REGIONAL JET   CRJ   \n",
       "3          0               0                   0  CANADAIR REGIONAL JET   CRJ   \n",
       "4          0               0                   0  CANADAIR REGIONAL JET   CRJ   \n",
       "\n",
       "   aicraft_age        time  tavg  tmin  tmax  prcp  snow   wdir  wspd    pres  \\\n",
       "0           17  2023-01-02   5.4   0.0  11.7   0.0   0.0  353.0   3.6  1019.6   \n",
       "1           17  2023-01-03   8.4   7.2   9.4  15.2   0.0   50.0   5.0  1013.9   \n",
       "2           16  2023-01-04  11.1   6.7  17.2   0.0   0.0  302.0   4.7  1009.8   \n",
       "3           17  2023-01-05  12.7   6.7  14.4   7.9   0.0  292.0   7.2  1013.0   \n",
       "4           16  2023-01-06   5.8   2.8   7.2   5.8   0.0  308.0   9.0  1016.6   \n",
       "\n",
       "  airport_id  \n",
       "0        ABE  \n",
       "1        ABE  \n",
       "2        ABE  \n",
       "3        ABE  \n",
       "4        ABE  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8aee353b-cfc2-4a93-9193-be3c44de28b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_flights(dataframe, dep_airport_col='dep_airport', date_col='flightdate', n_flights=10):\n",
    "    dataframe[date_col] = pd.to_datetime(dataframe[date_col])\n",
    "\n",
    "    # Group by dep_airport and date\n",
    "    grouped = dataframe.groupby([dep_airport_col, date_col])\n",
    "\n",
    "    # Sample 10 flights from each group, allowing replacement if a group has fewer rows\n",
    "    sampled_data = grouped.apply(lambda x: x.sample(n=n_flights, replace=len(x) < n_flights)).reset_index(drop=True)\n",
    "\n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cb9b993-c65c-4588-9136-68c3015f5815",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1192190, 34)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sample_flights(df, dep_airport_col='dep_airport', date_col='flightdate', n_flights=10)\n",
    "\n",
    "# Verify the sampling\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "009b1cfd-2d79-4c74-a6dd-fcd7f6cd248b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685d6d9a-8d58-4b35-a5cd-d919dc3c876f",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0df3c54-8357-458c-8a7b-97d3df836f93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flightdate', 'timestamp'),\n",
       " ('day_of_week', 'bigint'),\n",
       " ('airline', 'string'),\n",
       " ('tail_number', 'string'),\n",
       " ('dep_airport', 'string'),\n",
       " ('dep_cityname', 'string'),\n",
       " ('deptime_label', 'string'),\n",
       " ('dep_delay', 'bigint'),\n",
       " ('dep_delay_tag', 'bigint'),\n",
       " ('dep_delay_type', 'string'),\n",
       " ('arr_airport', 'string'),\n",
       " ('arr_cityname', 'string'),\n",
       " ('arr_delay', 'bigint'),\n",
       " ('arr_delay_type', 'string'),\n",
       " ('flight_duration', 'bigint'),\n",
       " ('distance_type', 'string'),\n",
       " ('delay_carrier', 'bigint'),\n",
       " ('delay_weather', 'bigint'),\n",
       " ('delay_nas', 'bigint'),\n",
       " ('delay_security', 'bigint'),\n",
       " ('delay_lastaircraft', 'bigint'),\n",
       " ('manufacturer', 'string'),\n",
       " ('model', 'string'),\n",
       " ('aicraft_age', 'bigint'),\n",
       " ('time', 'string'),\n",
       " ('tavg', 'double'),\n",
       " ('tmin', 'double'),\n",
       " ('tmax', 'double'),\n",
       " ('prcp', 'double'),\n",
       " ('snow', 'double'),\n",
       " ('wdir', 'double'),\n",
       " ('wspd', 'double'),\n",
       " ('pres', 'double'),\n",
       " ('airport_id', 'string')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "375683eb-17f0-45a6-8d55-c69c3cd27a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"time\", \"airport_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c2e62c7-410e-4373-8a43-7eab0f9f97e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_cols = [col for col, dtype in df.dtypes if dtype in [\"double\", \"bigint\", \"int\"]]\n",
    "\n",
    "cat_cols = [col for col, dtype in df.dtypes if dtype in [\"string\", \"timestamp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52266250-2a20-4331-8f45-fbb29ddc4829",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns: ['day_of_week', 'dep_delay', 'dep_delay_tag', 'arr_delay', 'flight_duration', 'delay_carrier', 'delay_weather', 'delay_nas', 'delay_security', 'delay_lastaircraft', 'aicraft_age', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'pres'] with count of 19 \n",
      "\n",
      "Categorical Columns: ['flightdate', 'airline', 'tail_number', 'dep_airport', 'dep_cityname', 'deptime_label', 'dep_delay_type', 'arr_airport', 'arr_cityname', 'arr_delay_type', 'distance_type', 'manufacturer', 'model'] with count of 13\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numerical Columns: {num_cols} with count of {len(num_cols)}\",\"\\n\")\n",
    "\n",
    "print(f\"Categorical Columns: {cat_cols} with count of {len(cat_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4eb795-0767-45b7-8293-d7a13843832e",
   "metadata": {},
   "source": [
    "## Train Model (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6976e3fe-7dc4-4b1f-85fc-a80c69a1c66d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_data(X_train, X_test, encoder_type='label', columns=None):\n",
    "    if columns is None:\n",
    "        # Default to all string (categorical) columns if no columns are specified\n",
    "        columns = [coll for coll, dtype in X_train.dtypes if dtype == 'string']\n",
    "\n",
    "    stages = []  # List to store transformation stages\n",
    "\n",
    "    for coll in columns:\n",
    "        if encoder_type == 'label':\n",
    "            # Label Encoding\n",
    "            indexer = StringIndexer(inputCol=coll, outputCol=f\"{coll}_indexed\", handleInvalid=\"keep\")\n",
    "            stages.append(indexer)\n",
    "        elif encoder_type == 'onehot':\n",
    "            # One-Hot Encoding\n",
    "            indexer = StringIndexer(inputCol=coll, outputCol=f\"{coll}_indexed\", handleInvalid=\"keep\")\n",
    "            onehot_encoder = OneHotEncoder(inputCol=f\"{coll}_indexed\", outputCol=f\"{coll}_encoded\")\n",
    "            stages.append(indexer)\n",
    "            stages.append(onehot_encoder)\n",
    "\n",
    "    # Create a Pipeline with all the stages\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "\n",
    "    # Fit the pipeline on the training data\n",
    "    pipeline_model = pipeline.fit(X_train)\n",
    "\n",
    "    # Transform both train and test data\n",
    "    X_train_encoded = pipeline_model.transform(X_train)\n",
    "    X_test_encoded = pipeline_model.transform(X_test)\n",
    "\n",
    "    return X_train_encoded, X_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "737978cc-4b9f-44f7-8127-82f3f21b8d0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_target(y_train, y_test, encoder_type='label'):\n",
    "    if encoder_type == 'label':\n",
    "        # Combine y_train and y_test for consistent encoding\n",
    "        combined_df = y_train.union(y_test)\n",
    "\n",
    "        # StringIndexer for label encoding\n",
    "        indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_indexed\")\n",
    "        indexer_model = indexer.fit(combined_df)  # Fit on combined data to ensure consistency\n",
    "\n",
    "        # Transform training and testing data\n",
    "        y_train_encoded = indexer_model.transform(y_train)\n",
    "        y_test_encoded = indexer_model.transform(y_test)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid encoder_type. Currently supported: 'label'.\")\n",
    "\n",
    "    return y_train_encoded, y_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccc4d1be-1a3a-473f-8b36-ef9515dd111c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_data(X_train, X_test, scaler_type='standard'):\n",
    "    # Step 1: Choose the appropriate scaler\n",
    "    if scaler_type == 'standard':\n",
    "        scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
    "    elif scaler_type == 'minmax':\n",
    "        scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "    elif scaler_type == 'robust':\n",
    "        scaler = RobustScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid scaler_type. Choose from 'standard', 'minmax', 'robust'.\")\n",
    "\n",
    "    # Step 2: Create a Pipeline\n",
    "    pipeline = Pipeline(stages=[scaler])\n",
    "\n",
    "    # Step 3: Fit the pipeline on the training data\n",
    "    pipeline_model = pipeline.fit(X_train)\n",
    "\n",
    "    # Step 4: Transform both train and test data\n",
    "    X_train_scaled = pipeline_model.transform(X_train).drop(\"features\").withColumnRenamed(\"scaled_features\", \"features\")\n",
    "    X_test_scaled = pipeline_model.transform(X_test).drop(\"features\").withColumnRenamed(\"scaled_features\", \"features\")\n",
    "\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d9b8af9-e616-4287-beb9-1bff5e96d0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_classification_models(X_train, y_train, X_test, y_test, models):\n",
    "    # Combine features and labels into single DataFrames\n",
    "    train_data = X_train.join(y_train, \"id\")\n",
    "    test_data = X_test.join(y_test, \"id\")\n",
    "\n",
    "    model_results = []\n",
    "    trained_models = {}\n",
    "\n",
    "    for model in models:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Train the model using a pipeline\n",
    "        pipeline = Pipeline(stages=[model])\n",
    "        trained_model = pipeline.fit(train_data)\n",
    "        trained_models[model.__class__.__name__] = trained_model\n",
    "\n",
    "        # Make predictions on both train and test datasets\n",
    "        predictions = trained_model.transform(test_data)\n",
    "\n",
    "        # Define evaluators for metrics\n",
    "        evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "        evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "        evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "        evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "        evaluator_roc = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "        evaluator_pr = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
    "\n",
    "        # Calculate metrics for test data\n",
    "        accuracy = evaluator_accuracy.evaluate(predictions)\n",
    "        f1_score = evaluator_f1.evaluate(predictions)\n",
    "        precision = evaluator_precision.evaluate(predictions)\n",
    "        recall = evaluator_recall.evaluate(predictions)\n",
    "        roc_auc = evaluator_roc.evaluate(predictions)\n",
    "        pr_auc = evaluator_pr.evaluate(predictions)\n",
    "\n",
    "        inference_time = time.time() - start_time  # Inference time in seconds\n",
    "\n",
    "        # Log results\n",
    "        print(f\"{model.__class__.__name__} is ready\")\n",
    "\n",
    "        model_results.append({\n",
    "            \"Model-Name\": model.__class__.__name__,\n",
    "            \"Test_Accuracy\": accuracy,\n",
    "            \"F1_Score\": f1_score,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"ROC_AUC\": roc_auc,\n",
    "            \"PR_AUC\": pr_auc,\n",
    "            \"Inference Time (ms)\": inference_time * 1000\n",
    "        })\n",
    "\n",
    "    # Convert results to a pandas DataFrame\n",
    "    models_df = pd.DataFrame(model_results)\n",
    "    models_df = models_df.set_index(\"Model-Name\")\n",
    "\n",
    "    return models_df.sort_values(\"Test_Accuracy\", ascending=False), trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc791ac5-4897-42a0-80cf-4f47294ed80b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_classification_metrics(y_true, y_pred, target_names=None, display=True):\n",
    "    # Ensure the columns are named correctly for PySpark evaluation\n",
    "    data = y_true.join(y_pred, \"id\")\n",
    "\n",
    "    # Initialize evaluators\n",
    "    evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "    evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "    evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = evaluator_accuracy.evaluate(data)\n",
    "    f1_score = evaluator_f1.evaluate(data)\n",
    "    precision = evaluator_precision.evaluate(data)\n",
    "    recall = evaluator_recall.evaluate(data)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm_df = data.groupBy(\"label\", \"prediction\").count().toPandas()\n",
    "    cm = pd.crosstab(cm_df[\"label\"], cm_df[\"prediction\"], values=cm_df[\"count\"], aggfunc=\"sum\").fillna(0).to_numpy()\n",
    "\n",
    "    # Normalized confusion matrix\n",
    "    cm_normalized = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Optionally display confusion matrix\n",
    "    if display:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=target_names, yticklabels=target_names)\n",
    "        plt.title(\"Normalized Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        plt.show()\n",
    "\n",
    "    # Generate classification report\n",
    "    if target_names is None:\n",
    "        target_names = [str(i) for i in range(cm.shape[0])]\n",
    "\n",
    "    classification_report_df = pd.DataFrame({\n",
    "        \"Precision\": cm.diagonal() / cm.sum(axis=0),\n",
    "        \"Recall\": cm.diagonal() / cm.sum(axis=1),\n",
    "        \"F1-Score\": 2 * (cm.diagonal() / cm.sum(axis=0)) * (cm.diagonal() / cm.sum(axis=1)) /\n",
    "                        ((cm.diagonal() / cm.sum(axis=0)) + (cm.diagonal() / cm.sum(axis=1))),\n",
    "    }, index=target_names).fillna(0)\n",
    "\n",
    "    # Return results in a dictionary\n",
    "    evaluation_results = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1 Score\": f1_score,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"Confusion Matrix\": cm,\n",
    "        \"Confusion Matrix Normalized\": cm_normalized,\n",
    "        \"Classification Report\": classification_report_df,\n",
    "    }\n",
    "\n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c045a4e9-f43b-4158-8b1d-d443e5241b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classification_models = [\n",
    "    LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10, regParam=0.01),\n",
    "\n",
    "    RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=50, seed=42),\n",
    "\n",
    "    GBTClassifier(featuresCol=\"features\", labelCol=\"label\", maxIter=10, seed=42),\n",
    "\n",
    "    DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\", maxDepth=5, seed=42),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e53292d-02c1-4d86-a401-540493a04f74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine X and y into a single DataFrame\n",
    "data = df.select(\n",
    "    *[col(c) for c in df.columns if c not in [\n",
    "        'dep_delay', \"flightdate\", \"tail_number\", \"deptime_label\",\n",
    "        \"dep_airport\", \"dep_cityname\", \"tmin\", \"tmax\", \"day_of_week\",\n",
    "        \"delay_carrier\", \"delay_nas\", \"delay_security\", \"delay_lastaircraft\", \"delay_weather\"\n",
    "    ]],  # Keep only desired columns\n",
    ").withColumn(\"label\", col(\"dep_delay_tag\").cast(DoubleType()))  # Set 'label' column as target variable\n",
    "\n",
    "# Drop the original target column to avoid duplication\n",
    "data = data.drop(\"dep_delay_tag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59c4b24b-9f68-481a-93c0-d9c9c78f5800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.withColumn(\"id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2570534d-60c9-4620-80bc-9959a9e1c1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('airline', 'string'),\n",
       " ('dep_delay_type', 'string'),\n",
       " ('arr_airport', 'string'),\n",
       " ('arr_cityname', 'string'),\n",
       " ('arr_delay', 'bigint'),\n",
       " ('arr_delay_type', 'string'),\n",
       " ('flight_duration', 'bigint'),\n",
       " ('distance_type', 'string'),\n",
       " ('manufacturer', 'string'),\n",
       " ('model', 'string'),\n",
       " ('aicraft_age', 'bigint'),\n",
       " ('tavg', 'double'),\n",
       " ('prcp', 'double'),\n",
       " ('snow', 'double'),\n",
       " ('wdir', 'double'),\n",
       " ('wspd', 'double'),\n",
       " ('pres', 'double'),\n",
       " ('label', 'double'),\n",
       " ('id', 'bigint')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5da0207f-9576-40d7-9558-997599820e2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_columns = [col for col, dtype in data.dtypes if dtype in ['double', 'bigint'] and col != 'label']\n",
    "vector_assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "data = vector_assembler.transform(data).select(\"id\", \"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4587c9ee-1ec9-409f-bc60-6435f977fdb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "X_train = train_data.select(\"id\", \"features\")\n",
    "y_train = train_data.select(\"id\", \"label\")\n",
    "X_test = test_data.select(\"id\", \"features\")\n",
    "y_test = test_data.select(\"id\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f42f429-db72-45ec-9de2-81a60992f79d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_encoded, X_test_encoded = encode_data(X_train, X_test, encoder_type='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c21853e-ebc6-40ae-8840-00377c60c0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "y_train_encoded, y_test_encoded = encode_target(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "583850a8-b5d9-46f1-ba64-a575437e71a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBTClassifier is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier is ready\n"
     ]
    }
   ],
   "source": [
    "models_class_no_s, trained_no_s = evaluate_classification_models(X_train_encoded, y_train_encoded, X_test_encoded,\n",
    "                                                                 y_test_encoded, classification_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2f3828a-416a-4f64-84ec-e3669aeb9281",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>PR_AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBTClassifier</th>\n",
       "      <td>86.021492</td>\n",
       "      <td>0.854426</td>\n",
       "      <td>0.857759</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.911473</td>\n",
       "      <td>0.847184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>85.839322</td>\n",
       "      <td>0.851542</td>\n",
       "      <td>0.856652</td>\n",
       "      <td>0.858393</td>\n",
       "      <td>0.581556</td>\n",
       "      <td>0.601451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>85.493827</td>\n",
       "      <td>0.852436</td>\n",
       "      <td>0.851761</td>\n",
       "      <td>0.854938</td>\n",
       "      <td>0.889565</td>\n",
       "      <td>0.815149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>82.658258</td>\n",
       "      <td>0.804332</td>\n",
       "      <td>0.841473</td>\n",
       "      <td>0.826583</td>\n",
       "      <td>0.902222</td>\n",
       "      <td>0.823721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Test_Accuracy  F1_Score  Precision    Recall  \\\n",
       "Model-Name                                                             \n",
       "GBTClassifier               86.021492  0.854426   0.857759  0.860215   \n",
       "DecisionTreeClassifier      85.839322  0.851542   0.856652  0.858393   \n",
       "RandomForestClassifier      85.493827  0.852436   0.851761  0.854938   \n",
       "LogisticRegression          82.658258  0.804332   0.841473  0.826583   \n",
       "\n",
       "                         ROC_AUC    PR_AUC  \n",
       "Model-Name                                  \n",
       "GBTClassifier           0.911473  0.847184  \n",
       "DecisionTreeClassifier  0.581556  0.601451  \n",
       "RandomForestClassifier  0.889565  0.815149  \n",
       "LogisticRegression      0.902222  0.823721  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_class_no_s.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2636e2b-f006-403c-b759-d7b9168cb6b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "X_train_ss, X_test_ss = scale_data(X_train_encoded, X_test_encoded, scaler_type=\"standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f17ccaa-d44d-41a7-af58-57e464b1fe8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBTClassifier is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier is ready\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>PR_AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GBTClassifier</th>\n",
       "      <td>85.930197</td>\n",
       "      <td>0.854460</td>\n",
       "      <td>0.856159</td>\n",
       "      <td>0.859302</td>\n",
       "      <td>0.911295</td>\n",
       "      <td>0.846760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>85.760172</td>\n",
       "      <td>0.853355</td>\n",
       "      <td>0.854142</td>\n",
       "      <td>0.857602</td>\n",
       "      <td>0.546663</td>\n",
       "      <td>0.577991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>85.402114</td>\n",
       "      <td>0.850959</td>\n",
       "      <td>0.850521</td>\n",
       "      <td>0.854021</td>\n",
       "      <td>0.889012</td>\n",
       "      <td>0.815840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>82.658258</td>\n",
       "      <td>0.804332</td>\n",
       "      <td>0.841473</td>\n",
       "      <td>0.826583</td>\n",
       "      <td>0.902223</td>\n",
       "      <td>0.823724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Test_Accuracy  F1_Score  Precision    Recall  \\\n",
       "Model-Name                                                             \n",
       "GBTClassifier               85.930197  0.854460   0.856159  0.859302   \n",
       "DecisionTreeClassifier      85.760172  0.853355   0.854142  0.857602   \n",
       "RandomForestClassifier      85.402114  0.850959   0.850521  0.854021   \n",
       "LogisticRegression          82.658258  0.804332   0.841473  0.826583   \n",
       "\n",
       "                         ROC_AUC    PR_AUC  \n",
       "Model-Name                                  \n",
       "GBTClassifier           0.911295  0.846760  \n",
       "DecisionTreeClassifier  0.546663  0.577991  \n",
       "RandomForestClassifier  0.889012  0.815840  \n",
       "LogisticRegression      0.902223  0.823724  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_class_ss, trained_ss = evaluate_classification_models(X_train_ss, y_train_encoded, X_test_ss,\n",
    "                                                             y_test_encoded, classification_models)\n",
    "\n",
    "models_class_ss.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b6de56c-f2c4-4929-891f-e71b58d97860",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "X_train_sm, X_test_sm = scale_data(X_train_encoded, X_test_encoded, scaler_type=\"minmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b807c7d-afca-4352-bd21-d4efe4bea186",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier is ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.                         (0 + 4) / 4]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o3423.evaluate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m models_class_mm, trained_mm \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_classification_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_sm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                             \u001b[49m\u001b[43my_test_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification_models\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m models_class_mm\u001b[38;5;241m.\u001b[39miloc[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[31], line 29\u001b[0m, in \u001b[0;36mevaluate_classification_models\u001b[0;34m(X_train, y_train, X_test, y_test, models)\u001b[0m\n\u001b[1;32m     26\u001b[0m evaluator_pr \u001b[38;5;241m=\u001b[39m BinaryClassificationEvaluator(labelCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, rawPredictionCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrawPrediction\u001b[39m\u001b[38;5;124m\"\u001b[39m, metricName\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mareaUnderPR\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Calculate metrics for test data\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator_accuracy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     30\u001b[0m f1_score \u001b[38;5;241m=\u001b[39m evaluator_f1\u001b[38;5;241m.\u001b[39mevaluate(predictions)\n\u001b[1;32m     31\u001b[0m precision \u001b[38;5;241m=\u001b[39m evaluator_precision\u001b[38;5;241m.\u001b[39mevaluate(predictions)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/ml/evaluation.py:111\u001b[0m, in \u001b[0;36mEvaluator.evaluate\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_evaluate(dataset)\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/ml/evaluation.py:148\u001b[0m, in \u001b[0;36mJavaEvaluator._evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    192\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/protocol.py:334\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m                 \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m answer[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o3423.evaluate"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    }
   ],
   "source": [
    "models_class_mm, trained_mm = evaluate_classification_models(X_train_sm, y_train_encoded, X_test_sm,\n",
    "                                                             y_test_encoded, classification_models)\n",
    "\n",
    "models_class_mm.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe494f-1712-448b-bd17-918ad34868a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_sr, X_test_sr = scale_data(X_train_encoded, X_test_encoded, scaler_type=\"robust\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e74a38-39e9-41ca-bf11-df202e2cca54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_class_rs, trained_rs = evaluate_classification_models(X_train_sr, y_train_encoded, X_test_sr,\n",
    "                                                             y_test_encoded, classification_models)\n",
    "\n",
    "models_class_rs.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c139b4-2739-4b40-923a-dd9fe20d3a98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_class_no_s[\"Scaler\"] = \"No Scaling\"\n",
    "models_class_ss[\"Scaler\"] = \"Standard Scaler\"\n",
    "models_class_mm[\"Scaler\"] = \"MinMax Scaler\"\n",
    "models_class_rs[\"Scaler\"] = \"Robust Scaler\"\n",
    "\n",
    "\n",
    "all_models = pd.concat([models_class_no_s, models_class_ss, models_class_mm, models_class_rs], axis=0)\n",
    "all_models = all_models.sort_values(by=\"Test_Accuracy\", ascending=False)\n",
    "all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c501bcd5-e68b-4267-88b7-17837a7f1157",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
